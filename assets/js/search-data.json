{
  
    
        "post0": {
            "title": "Title",
            "content": "from fastai.vision.all import * . path = Path(&quot;/home/james/ml/Kaggle&quot;) #path = Path(&quot;/home/james/ml/mitosis/&quot;) . path . Path(&#39;/home/james/ml/Kaggle&#39;) . train_path = path/&quot;train/&quot; val_path = path/&quot;val/&quot; test_path = path/&quot;test/&quot; train_path, val_path, test_path . (Path(&#39;/home/james/ml/Kaggle/train&#39;), Path(&#39;/home/james/ml/Kaggle/val&#39;), Path(&#39;/home/james/ml/Kaggle/test&#39;)) . train_fnames = get_image_files(train_path) val_fnames = get_image_files(val_path) test_fnames = get_image_files(test_path) all_files = get_image_files(path) L(train_fnames, val_fnames, test_fnames, all_files).map(len) . (#4) [5216,16,624,5856] . train_fnames[0] . Path(&#39;/home/james/ml/Kaggle/train/NORMAL/NORMAL2-IM-0730-0001.jpeg&#39;) . train_idxs = [i for i, fname in enumerate(all_files) if &quot;train&quot; in str(fname)] val_idxs = [i for i, fname in enumerate(all_files) if &quot;val&quot; in str(fname)] . augs = [RandomResizedCropGPU(size=224, min_scale=0.75), Rotate(), Zoom()] . dblock = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock), splitter=lambda x: [train_idxs, val_idxs], get_y=parent_label, item_tfms=Resize(512, method=&quot;squish&quot;), batch_tfms=augs, ) . dls = dblock.dataloaders(all_files) dls.show_batch() . xb, yb = first(dls.train) xb.shape, yb.shape . (torch.Size([64, 3, 224, 224]), torch.Size([64])) . (xb[0, 0] == xb[0, 1]).float().mean(), (xb[0, 1] == xb[0, 2]).float().mean() . (TensorImage(1., device=&#39;cuda:0&#39;), TensorImage(1., device=&#39;cuda:0&#39;)) . metrics = [accuracy, F1Score()] . learn_naive = cnn_learner(dls, resnet18, pretrained=False, metrics = metrics) learn_naive.lr_find() . SuggestedLRs(lr_min=0.006918309628963471, lr_steep=1.0964781722577754e-06) . learn_naive.fit_one_cycle(10, 3e-2) . epoch train_loss valid_loss accuracy f1_score time . 0 | 0.348231 | 5.128016 | 0.500000 | 0.666667 | 00:16 | . 1 | 0.362527 | 1.862413 | 0.625000 | 0.666667 | 00:16 | . 2 | 0.312113 | 0.981786 | 0.687500 | 0.545455 | 00:16 | . 3 | 0.225482 | 0.820239 | 0.625000 | 0.571429 | 00:16 | . 4 | 0.167533 | 0.527764 | 0.750000 | 0.750000 | 00:16 | . 5 | 0.138492 | 0.528889 | 0.625000 | 0.700000 | 00:16 | . 6 | 0.126504 | 0.853472 | 0.687500 | 0.761905 | 00:16 | . 7 | 0.115164 | 0.711195 | 0.750000 | 0.777778 | 00:17 | . 8 | 0.103236 | 0.703458 | 0.750000 | 0.777778 | 00:16 | . 9 | 0.083329 | 0.845677 | 0.625000 | 0.700000 | 00:16 | . normal_cases = L(fname for fname in train_fnames if &quot;NORMAL&quot; in str(fname)) oversampled_files = train_fnames + (normal_cases * 2) + val_fnames . L(train_fnames, val_fnames, test_fnames, all_files, normal_cases, oversampled_files).map(len) . (#6) [5216,16,624,5856,1341,7914] . train_idxs = [i for i, fname in enumerate(oversampled_files) if &quot;train&quot; in str(fname)] val_idxs = [i for i, fname in enumerate(oversampled_files) if &quot;val&quot; in str(fname)] . len(train_idxs), len(val_idxs) . (7898, 16) . augs = [RandomResizedCropGPU(size=224, min_scale=0.75), Rotate(), Zoom()] dblock = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock), splitter=lambda x: [train_idxs, val_idxs], get_y=parent_label, item_tfms=Resize(512, method=&quot;squish&quot;), batch_tfms=augs, ) . dls = dblock.dataloaders(oversampled_files) #oversampled files! dls.show_batch() . xb, yb = first(dls.train) xb.shape, yb.shape . (torch.Size([64, 3, 224, 224]), torch.Size([64])) . (xb[0, 0] == xb[0, 1]).float().mean(), (xb[0, 1] == xb[0, 2]).float().mean() metrics = [accuracy, F1Score()] . learn_naive = cnn_learner(dls, resnet18, pretrained=False, metrics = metrics) learn_naive.lr_find() . SuggestedLRs(lr_min=0.006918309628963471, lr_steep=5.754399353463668e-06) . learn_naive.fit_one_cycle(10, 2e-2) . epoch train_loss valid_loss accuracy f1_score time . 0 | 0.266269 | 45.171726 | 0.500000 | 0.000000 | 00:25 | . 1 | 0.307405 | 42.273010 | 0.500000 | 0.000000 | 00:24 | . 2 | 0.209529 | 3.454804 | 0.500000 | 0.666667 | 00:25 | . 3 | 0.188415 | 1.032762 | 0.625000 | 0.727273 | 00:25 | . 4 | 0.138224 | 1.265054 | 0.562500 | 0.695652 | 00:25 | . 5 | 0.140918 | 0.885906 | 0.625000 | 0.700000 | 00:25 | . 6 | 0.105409 | 0.868151 | 0.562500 | 0.695652 | 00:24 | . 7 | 0.102466 | 0.268569 | 0.875000 | 0.888889 | 00:25 | . 8 | 0.084992 | 0.135179 | 1.000000 | 1.000000 | 00:25 | . 9 | 0.067952 | 0.115590 | 1.000000 | 1.000000 | 00:24 | . normal_cases = L(fname for fname in train_fnames if &quot;NORMAL&quot; in str(fname)) oversampled_files = train_fnames + normal_cases*2 + val_fnames + test_fnames # adding the test set file names train_idxs = [i for i, fname in enumerate(oversampled_files) if &quot;train&quot; in str(fname)] val_idxs = [i for i, fname in enumerate(oversampled_files) if &quot;train&quot; not in str(fname)] # obtaining their indices . augs = [RandomResizedCropGPU(size=224, min_scale=0.75), Rotate(), Zoom()] dblock = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock), splitter=lambda x: [train_idxs, val_idxs], get_y=parent_label, item_tfms=Resize(512, method=&quot;squish&quot;), batch_tfms=augs, ) . dls = dblock.dataloaders(oversampled_files) metrics = [accuracy, F1Score(), Precision(), Recall()] (xb[0, 0] == xb[0, 1]).float().mean(), (xb[0, 1] == xb[0, 2]).float().mean() . (TensorImage(1., device=&#39;cuda:0&#39;), TensorImage(1., device=&#39;cuda:0&#39;)) . learn_naive = cnn_learner(dls, resnet18, pretrained=False, metrics = metrics) learn_naive.lr_find() . SuggestedLRs(lr_min=0.00831763744354248, lr_steep=9.12010818865383e-07) . learn_naive.fit_one_cycle(10, 3e-3) . epoch train_loss valid_loss accuracy f1_score precision_score recall_score time . 0 | 0.303451 | 1.041959 | 0.770312 | 0.798354 | 0.879154 | 0.731156 | 00:26 | . 1 | 0.239696 | 27.300236 | 0.381250 | 0.010000 | 1.000000 | 0.005025 | 00:27 | . 2 | 0.164620 | 1.893282 | 0.626562 | 0.769082 | 0.624804 | 1.000000 | 00:27 | . 3 | 0.161303 | 0.298090 | 0.890625 | 0.914634 | 0.888626 | 0.942211 | 00:27 | . 4 | 0.130197 | 0.830376 | 0.779688 | 0.848224 | 0.741996 | 0.989950 | 00:27 | . 5 | 0.113178 | 0.406022 | 0.837500 | 0.856749 | 0.948171 | 0.781407 | 00:27 | . 6 | 0.099189 | 0.390802 | 0.876562 | 0.909091 | 0.838641 | 0.992462 | 00:27 | . 7 | 0.087346 | 0.374241 | 0.873438 | 0.905263 | 0.846827 | 0.972362 | 00:27 | . 8 | 0.061072 | 0.209378 | 0.926562 | 0.941904 | 0.927007 | 0.957286 | 00:27 | . 9 | 0.051871 | 0.284719 | 0.903125 | 0.926190 | 0.880090 | 0.977387 | 00:27 | . means = [xb.mean(dim=(0, 2, 3)) for xb, yb in dls.train] stds = [xb.std(dim=(0, 2, 3)) for xb, yb in dls.train] mean, std = torch.stack(means).mean(dim=0), torch.stack(stds).mean(dim=0) print(mean, std) . TensorImage([0.5158, 0.5158, 0.5158], device=&#39;cuda:0&#39;) TensorImage([0.2083, 0.2083, 0.2083], device=&#39;cuda:0&#39;) . augs = [RandomResizedCropGPU(size=224, min_scale=0.75), Rotate(), Zoom()] augs += [Normalize.from_stats(mean, std)] dblock = DataBlock(blocks=(ImageBlock(cls=PILImage), CategoryBlock), splitter=lambda x: [train_idxs, val_idxs], get_y=parent_label, item_tfms=Resize(512, method=&quot;squish&quot;), batch_tfms=augs, ) dls = dblock.dataloaders(oversampled_files) metrics = [accuracy, F1Score(), Precision(), Recall()] (xb[0, 0] == xb[0, 1]).float().mean(), (xb[0, 1] == xb[0, 2]).float().mean() . (TensorImage(1., device=&#39;cuda:0&#39;), TensorImage(1., device=&#39;cuda:0&#39;)) . learn_naive = cnn_learner(dls, resnet18, pretrained=False, metrics = metrics) learn_naive.lr_find() . SuggestedLRs(lr_min=0.010000000149011612, lr_steep=6.309573450380412e-07) . learn_naive.fit_one_cycle(10, 3e-3) . epoch train_loss valid_loss accuracy f1_score precision_score recall_score time . 0 | 0.361943 | 1.853415 | 0.676562 | 0.664506 | 0.936073 | 0.515075 | 00:27 | . 1 | 0.231008 | 0.603643 | 0.810938 | 0.841830 | 0.877384 | 0.809045 | 00:27 | . 2 | 0.172839 | 0.334549 | 0.898438 | 0.920245 | 0.899281 | 0.942211 | 00:27 | . 3 | 0.159654 | 0.363380 | 0.857813 | 0.879150 | 0.932394 | 0.831658 | 00:27 | . 4 | 0.133570 | 0.344489 | 0.896875 | 0.922170 | 0.868889 | 0.982412 | 00:27 | . 5 | 0.118196 | 0.541803 | 0.829687 | 0.878212 | 0.790744 | 0.987437 | 00:27 | . 6 | 0.094995 | 0.291310 | 0.901563 | 0.920152 | 0.928389 | 0.912060 | 00:27 | . 7 | 0.067081 | 0.991524 | 0.767187 | 0.841994 | 0.728440 | 0.997487 | 00:27 | . 8 | 0.065715 | 0.233278 | 0.910937 | 0.928482 | 0.927318 | 0.929648 | 00:27 | . 9 | 0.054239 | 0.289483 | 0.907812 | 0.930342 | 0.877506 | 0.989950 | 00:27 | . learn = cnn_learner(dls, resnet18, metrics = metrics) learn.lr_find() . learn.fit_one_cycle(5, 1e-3) . epoch train_loss valid_loss accuracy f1_score precision_score recall_score time . 0 | 0.321095 | 0.508212 | 0.853125 | 0.890187 | 0.831878 | 0.957286 | 00:26 | . 1 | 0.199258 | 0.391814 | 0.889063 | 0.914355 | 0.879350 | 0.952261 | 00:26 | . 2 | 0.114932 | 0.360986 | 0.900000 | 0.923261 | 0.883028 | 0.967337 | 00:26 | . 3 | 0.090028 | 0.374877 | 0.901563 | 0.925444 | 0.874720 | 0.982412 | 00:26 | . 4 | 0.083934 | 0.318357 | 0.912500 | 0.932367 | 0.897674 | 0.969849 | 00:26 | . learn.unfreeze() learn.lr_find() . SuggestedLRs(lr_min=6.309573450380412e-08, lr_steep=6.309573450380412e-07) . learn.fit_one_cycle(5, slice(1e-7, 1e-5)) . epoch train_loss valid_loss accuracy f1_score precision_score recall_score time . 0 | 0.087115 | 0.337621 | 0.907812 | 0.929172 | 0.889655 | 0.972362 | 00:27 | . 1 | 0.078587 | 0.403133 | 0.885938 | 0.914620 | 0.855580 | 0.982412 | 00:27 | . 2 | 0.078736 | 0.306424 | 0.910937 | 0.931076 | 0.897436 | 0.967337 | 00:27 | . 3 | 0.078821 | 0.386030 | 0.890625 | 0.917647 | 0.862832 | 0.979899 | 00:27 | . 4 | 0.080041 | 0.308522 | 0.909375 | 0.930120 | 0.893519 | 0.969849 | 00:27 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.print_classification_report() . precision recall f1-score support NORMAL 0.94 0.81 0.87 242 PNEUMONIA 0.89 0.97 0.93 398 accuracy 0.91 640 macro avg 0.92 0.89 0.90 640 weighted avg 0.91 0.91 0.91 640 .",
            "url": "https://jamcron.github.io/data_sci_blog/2021/12/15/Kaggle-pneumonia.html",
            "relUrl": "/2021/12/15/Kaggle-pneumonia.html",
            "date": " • Dec 15, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://jamcron.github.io/data_sci_blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://jamcron.github.io/data_sci_blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jamcron.github.io/data_sci_blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jamcron.github.io/data_sci_blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}